This repository is the official implementation of FSTINet, a novel framework designed for class-agnostic motion prediction in autonomous driving scenarios. FSTINet addresses key challenges in spatio-temporal dependency modeling and dynamic feature capture by integrating spatial-temporal dynamics with frequency-domain information, as proposed in the paper:FSTINet: Spatial-Temporal Integrated Network for Class-Agnostic Motion Prediction with Frequency-Spatial Fusion(Paper File: FSTINet___Yuzhuo_Feng___2025 (1).pdf | Code will be released soon)
Overview
Accurate motion prediction of traffic participants is a critical prerequisite for safe and efficient autonomous driving. Existing methods often face two core limitations:
Insufficient spatio-temporal dependency modeling: Conventional strategies (e.g., 3D max-pooling, global aggregation) easily lose long-term temporal dynamics and fine-grained local variations, leading to poor adaptability in high-speed scenarios.
Limited dynamic feature capture: Effective prediction requires balancing low-frequency global context and high-frequency local details, but existing approaches struggle to fuse these two types of features, often confusing subtle motion changes with background noise.
FSTINet resolves these issues by introducing two core modules that unify spatial, temporal, and frequency-domain information, achieving robust performance in complex dynamic environments
